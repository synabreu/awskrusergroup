# AWS Sagemaker를 이용한 MLOps와 LLMOps

안녕하세요? 서진호입니다. 

이번 주 AWSKR USER GROUP 의 데이터 모임 에서 발표한 자료를 공유해 드립니다.
주제는 "AWS Sagemaker를 이용한 MLOps 와 LLMOps" 로 2시간 정도 발표한 자료입니다.
그날 많은 분들이 질문을 주셔서 그것을 반영해서 좀더 추가적인 자료를 넣어서 작성했습니다.

제 1 부에서는 다음과 같은 내용으로 발표했습니다.

<p> • MLOps (AI/ML lifecycle) 및 AI/ML Stack • AWS SageMaker 2022.12 주요 기능 </p>
<p> • SageMaker Domain 및 User Profile • SageMaker Projects – Pipeline </p>
<p> • SageMaker Notebooks </p>
<p> • SageMaker Studio </p>
<p> • SageMaker Processing (전처리) </p>
<p> • SageMaker Autopilot (AutoML) </p>
<p> • SageMaker Training Jobs </p>
<p> • SageMaker Experiments 및 Trials </p>
<p> • SageMaker Serving and Deployment 
<p> • SageMaker Endpoints </p>
<p> • SageMaker Debugger </p>
<p> • SageMaker Monitor </p>
<p> • 실습: SageMaker Notebooks 에서 ML 모델을 ECR 배포 및 엔드포인트 </p>


제 2 부에서는 다음과 같은 내용으로 발표했습니다.

<p> • 생성 AI과 초거대 언어 모델(LLM) </p>
<p> • 생성 AI 생태계 </p>
<p> • 생성 AI 사용사례와 분야별 랜드스케이프 </p>
<p> • 초거대 언어 모델(LLM) 진영 </p>
<p> • 허깅 페이스 오픈 LLM 리더보드 </p>
<p> • MS/OpenAI 공동 전략, 구글 BARD(PaLM2) 과 AWS 생성 AI 전략 </p> 
<p> • LLM 기술 구조 – LLM 정의와 LLM 파운데이션 모델 </p>
<p> • 비공개 소스 GPT3 vs. 공개 소스 메타 LLaMA </p>
<p> • 오픈 소스 프레임워크: Auto-GPT 와 LangChain </p>
<p> • 국내 LLM 히스토리 – 한글 데이터셋 </p>
<p> • 생성 AI 애플리케이션 방법론 </p>
<p> • 초거대 언어 모델(LLM) 생명주기 </p>
<p> • 초거대 언어 모델(LLM) 아키텍처 </p>
<p> • LLM 프롬프트 및 태스크 </p>
<p> • 추론을 위한 생성형 환경 설정 파라미터 </p>
<p> • LLM 프롬프트 및 태스크 </p>
<p> • LLMOps 와 LLM 모델 개발 조언 </p>

그리고 demo_code 폴더에 관련 예제 소스를 수록했고, 소스에 주석을 달아 놓았습니다. 
혹시 작동시켜 보시다가 안되시면 언제든지 저에게 메일을 주시면 답변 드리도록 하겠습니다.

## Further Readings ##

1. [QLoRa: Fine-Tune a Large Language Model on Your GPU](https://towardsdatascience.com/qlora-fine-tune-a-large-language-model-on-your-gpu-27bed5a03e2b, "GPU를 가지고 LLM을 파인튜닝할 때 QLoRa 를 사용하면 성능도 향상되고 비용도 줄일 수 있음"): GPU를 가지고 LLM을 파인튜닝할 때 QLoRa 를 사용하면 성능도 향상되고 비용도 줄일 수 있음. 
2. 
