{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f923eaac-ee57-458c-ae30-3ea111fa8c5e",
   "metadata": {},
   "source": [
    "# 실습 데모: 커스텀 훈련 컨테이너 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b6aa5-69c0-44b3-ace6-0c10c5c38918",
   "metadata": {},
   "source": [
    "#### 2. 컨테이너 빌드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555703df-11a9-4035-a413-6cff6583a74b",
   "metadata": {},
   "source": [
    "#### 자체 학습 모델을 실행하려면 Amazon SageMaker Training Toolkit을 사용하여 Docker 컨테이너를 빌드할 때 반드시 Amazon SageMaker 노트북 인스턴스를 사용해야 한다. (Amazon Studio 에는 Docker 명령어가 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df40e7f-15a0-4cc1-91ee-b7d557162827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.167.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 버전 체크\n",
    "import sagemaker\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7be8c-263a-43c5-8457-1be2bdc3024f",
   "metadata": {},
   "source": [
    "#### 도커 빌드를 위해 dockerfile 에 있는 폴더로 이동\n",
    "#### 주의: 주석과 cd ~/SageMaker/docker_test_folder 명령어가 하의 셀이 있다면 syntax Error 발ㅇ함. --> Python / SageMaker 버그"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74123911-517d-4407-a298-c07678221e81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/docker_test_folder\n"
     ]
    }
   ],
   "source": [
    "cd ~/SageMaker/docker_test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c600c1d-7191-4ae5-ae66-8e4f3fc703bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/docker_test_folder\n"
     ]
    }
   ],
   "source": [
    "# 현재 디렉토리를 확인 (pwd = Print Working Directory)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582edfff-f6ff-498a-914d-9457dd183f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  6.656kB\n",
      "Step 1/4 : FROM tensorflow/tensorflow:latest-gpu-jupyter\n",
      "latest-gpu-jupyter: Pulling from tensorflow/tensorflow\n",
      "\n",
      "\u001b[1B351b9876: Pulling fs layer \n",
      "\u001b[1B47ab5eb5: Pulling fs layer \n",
      "\u001b[1B4004a3cd: Pulling fs layer \n",
      "\u001b[1Bef4b90c8: Pulling fs layer \n",
      "\u001b[1B5b7808f0: Pulling fs layer \n",
      "\u001b[1Bf27d9487: Pulling fs layer \n",
      "\u001b[1Bce5452b7: Pulling fs layer \n",
      "\u001b[1B96a5c562: Pulling fs layer \n",
      "\u001b[5B5b7808f0: Waiting fs layer \n",
      "\u001b[7Bef4b90c8: Waiting fs layer \n",
      "\u001b[6Bf27d9487: Waiting fs layer \n",
      "\u001b[1B2ebc3ac7: Pulling fs layer \n",
      "\u001b[1Bb9c327ea: Pulling fs layer \n",
      "\u001b[1B50d98969: Pulling fs layer \n",
      "\u001b[1B2b037de7: Pulling fs layer \n",
      "\u001b[1Bc4c4e2d5: Pulling fs layer \n",
      "\u001b[8B2fb4b02b: Waiting fs layer \n",
      "\u001b[8Baf93509e: Waiting fs layer \n",
      "\u001b[11B581227d: Waiting fs layer \n",
      "\u001b[7B50d98969: Waiting fs layer \n",
      "\u001b[1B23f80590: Pulling fs layer \n",
      "\u001b[8B2b037de7: Waiting fs layer \n",
      "\u001b[16B6a5c562: Waiting fs layer \n",
      "\u001b[1Bb700ef54: Pull complete   32B/32BB7MBB\u001b[23A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[21A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[24A\u001b[2K\u001b[24A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[23A\u001b[2K\u001b[22A\u001b[2K\u001b[16A\u001b[2K\u001b[22A\u001b[2K\u001b[16A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[22A\u001b[2K\u001b[11A\u001b[2K\u001b[22A\u001b[2K\u001b[11A\u001b[2K\u001b[22A\u001b[2K\u001b[11A\u001b[2K\u001b[22A\u001b[2K\u001b[11A\u001b[2K\u001b[22A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[11A\u001b[2K\u001b[16A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[16A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[4A\u001b[2K\u001b[11A\u001b[2K\u001b[4A\u001b[2K\u001b[11A\u001b[2K\u001b[4A\u001b[2K\u001b[11A\u001b[2K\u001b[4A\u001b[2K\u001b[11A\u001b[2K\u001b[4A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[3A\u001b[2K\u001b[15A\u001b[2K\u001b[3A\u001b[2K\u001b[11A\u001b[2K\u001b[3A\u001b[2K\u001b[15A\u001b[2K\u001b[3A\u001b[2K\u001b[15A\u001b[2K\u001b[3A\u001b[2K\u001b[15A\u001b[2K\u001b[3A\u001b[2K\u001b[15A\u001b[2K\u001b[2A\u001b[2K\u001b[15A\u001b[2K\u001b[1A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2KExtracting  46.79MB/2.522GB\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[14A\u001b[2K\u001b[14A\u001b[2K\u001b[13A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[12A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:64bfb25fd3f85e1b0af1757ef8ff25fb96a261d1e572a4105e3037d0a27cdf67\n",
      "Status: Downloaded newer image for tensorflow/tensorflow:latest-gpu-jupyter\n",
      " ---> 99c4601387b3\n",
      "Step 2/4 : RUN pip3 install sagemaker-training\n",
      " ---> Running in 04664e40ce41\n",
      "Collecting sagemaker-training\n",
      "  Downloading sagemaker_training-4.6.1.tar.gz (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 4.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (1.24.3)\n",
      "Collecting boto3 (from sagemaker-training)\n",
      "  Downloading boto3-1.28.14-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.8/135.8 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sagemaker-training) (1.14.0)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (23.1.2)\n",
      "Collecting retrying>=1.3.3 (from sagemaker-training)\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Collecting gevent (from sagemaker-training)\n",
      "  Downloading gevent-23.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 35.1 MB/s eta 0:00:00\n",
      "Collecting inotify_simple==1.2.1 (from sagemaker-training)\n",
      "  Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: werkzeug>=0.15.5 in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (2.3.6)\n",
      "Collecting paramiko>=2.4.2 (from sagemaker-training)\n",
      "  Downloading paramiko-3.2.0-py3-none-any.whl (224 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.2/224.2 kB 57.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil>=5.6.7 in /usr/local/lib/python3.8/dist-packages (from sagemaker-training) (5.9.5)\n",
      "Collecting protobuf<=3.20.3,>=3.9.2 (from sagemaker-training)\n",
      "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 12.1 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.2.2 (from sagemaker-training)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 18.4 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=3.2 (from paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 593.7/593.7 kB 7.9 MB/s eta 0:00:00\n",
      "Collecting cryptography>=3.3 (from paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading cryptography-41.0.2-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 41.5 MB/s eta 0:00:00\n",
      "Collecting pynacl>=1.5 (from paramiko>=2.4.2->sagemaker-training)\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 kB 15.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=0.15.5->sagemaker-training) (2.1.3)\n",
      "Collecting botocore<1.32.0,>=1.31.14 (from boto3->sagemaker-training)\n",
      "  Downloading botocore-1.31.14-py3-none-any.whl (11.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.1/11.1 MB 43.5 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->sagemaker-training)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->sagemaker-training)\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 24.9 MB/s eta 0:00:00\n",
      "Collecting zope.event (from gevent->sagemaker-training)\n",
      "  Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting zope.interface (from gevent->sagemaker-training)\n",
      "  Downloading zope.interface-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 249.2/249.2 kB 51.8 MB/s eta 0:00:00\n",
      "Collecting greenlet>=2.0.0 (from gevent->sagemaker-training)\n",
      "  Downloading greenlet-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 618.5/618.5 kB 6.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.32.0,>=1.31.14->boto3->sagemaker-training) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3/dist-packages (from botocore<1.32.0,>=1.31.14->boto3->sagemaker-training) (1.25.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.3->paramiko>=2.4.2->sagemaker-training) (1.15.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from zope.event->gevent->sagemaker-training) (68.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4.2->sagemaker-training) (2.21)\n",
      "Building wheels for collected packages: sagemaker-training, inotify_simple\n",
      "  Building wheel for sagemaker-training (setup.py): started\n",
      "  Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-training: filename=sagemaker_training-4.6.1-cp38-cp38-linux_x86_64.whl size=92652 sha256=24f6fa2d0413cef1ce22a011d1ab84b742af2ebbfea6847da472b83445fac04c\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/3c/eaf16fa6c6a720ee824bb9d15e5b6c2069c91d87f733797199\n",
      "  Building wheel for inotify_simple (setup.py): started\n",
      "  Building wheel for inotify_simple (setup.py): finished with status 'done'\n",
      "  Created wheel for inotify_simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8201 sha256=b4d50d79911c288cf82d02eade79d58c00c7c2fc42d86caef5d32d62ae7b0faf\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/2d/c2/46bac8503a2469925f6f463615984b3d1fe472e729363a28d3\n",
      "Successfully built sagemaker-training inotify_simple\n",
      "Installing collected packages: inotify_simple, zope.interface, zope.event, scipy, retrying, protobuf, jmespath, greenlet, bcrypt, pynacl, gevent, cryptography, botocore, s3transfer, paramiko, boto3, sagemaker-training\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.3\n",
      "    Uninstalling protobuf-4.23.3:\n",
      "      Successfully uninstalled protobuf-4.23.3\n",
      "Successfully installed bcrypt-4.0.1 boto3-1.28.14 botocore-1.31.14 cryptography-41.0.2 gevent-23.7.0 greenlet-2.0.2 inotify_simple-1.2.1 jmespath-1.0.1 paramiko-3.2.0 protobuf-3.20.3 pynacl-1.5.0 retrying-1.3.4 s3transfer-0.6.1 sagemaker-training-4.6.1 scipy-1.10.1 zope.event-5.0 zope.interface-6.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python3 -m pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 04664e40ce41\n",
      " ---> 62ff856baff2\n",
      "Step 3/4 : COPY train.py /opt/ml/code/train.py\n",
      " ---> 180433f95498\n",
      "Step 4/4 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Running in 711d2948ee49\n",
      "Removing intermediate container 711d2948ee49\n",
      " ---> 8bf1a121c329\n",
      "Successfully built 8bf1a121c329\n",
      "Successfully tagged tf-custom-container-test:latest\n"
     ]
    }
   ],
   "source": [
    "# 도커 빌드\n",
    "# 주의: Docker 컨테이너를 빌드하려면 끝에 마침표(.)가 있는 공백을 포함하여 다음 Docker 빌드 명령을 실행해야 한다.\n",
    "\n",
    "!docker build -t tf-custom-container-test ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd5df06-ad15-46d3-aa3c-5fe14735a95c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting docker-compose\n",
      "  Downloading docker_compose-1.29.2-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.8/114.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML<6,>=3.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from docker-compose) (5.4.1)\n",
      "Collecting distro<2,>=1.5.0 (from docker-compose)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: docker[ssh]>=5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from docker-compose) (6.1.3)\n",
      "Collecting dockerpty<1,>=0.4.1 (from docker-compose)\n",
      "  Downloading dockerpty-0.4.1.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docopt<1,>=0.6.1 (from docker-compose)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jsonschema<4,>=2.5.1 (from docker-compose)\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv<1,>=0.13.0 (from docker-compose)\n",
      "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from docker-compose) (2.29.0)\n",
      "Collecting texttable<2,>=0.9.0 (from docker-compose)\n",
      "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
      "Collecting websocket-client<1,>=0.32.0 (from docker-compose)\n",
      "  Downloading websocket_client-0.59.0-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from docker[ssh]>=5->docker-compose) (21.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from docker[ssh]>=5->docker-compose) (1.26.14)\n",
      "Collecting paramiko>=2.4.3 (from docker[ssh]>=5->docker-compose)\n",
      "  Downloading paramiko-3.2.0-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from dockerpty<1,>=0.4.1->docker-compose) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonschema<4,>=2.5.1->docker-compose) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonschema<4,>=2.5.1->docker-compose) (0.19.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonschema<4,>=2.5.1->docker-compose) (67.7.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2.20.0->docker-compose) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2.20.0->docker-compose) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2.20.0->docker-compose) (2023.5.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from packaging>=14.0->docker[ssh]>=5->docker-compose) (3.0.9)\n",
      "Collecting bcrypt>=3.2 (from paramiko>=2.4.3->docker[ssh]>=5->docker-compose)\n",
      "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.2/593.2 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=3.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from paramiko>=2.4.3->docker[ssh]>=5->docker-compose) (40.0.2)\n",
      "Collecting pynacl>=1.5 (from paramiko>=2.4.3->docker[ssh]>=5->docker-compose)\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from cryptography>=3.3->paramiko>=2.4.3->docker[ssh]>=5->docker-compose) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4.3->docker[ssh]>=5->docker-compose) (2.21)\n",
      "Building wheels for collected packages: dockerpty, docopt\n",
      "  Building wheel for dockerpty (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dockerpty: filename=dockerpty-0.4.1-py3-none-any.whl size=16600 sha256=7446dedf95e38daa0f144da4ebdc3a7d929b5fa85d3d96512e458a546dbab7ea\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/18/00/32/f75cd03098074f988a01c59a2e3a55ae9c0773eb66acb4cb5e\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=f56d7f8f226119bfbb19e62451f1d775c3b4991741e61fce76074a5d3aa606c3\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built dockerpty docopt\n",
      "Installing collected packages: texttable, docopt, websocket-client, python-dotenv, jsonschema, dockerpty, distro, bcrypt, pynacl, paramiko, docker-compose\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 1.5.1\n",
      "    Uninstalling websocket-client-1.5.1:\n",
      "      Successfully uninstalled websocket-client-1.5.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.17.3\n",
      "    Uninstalling jsonschema-4.17.3:\n",
      "      Successfully uninstalled jsonschema-4.17.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab-server 2.22.1 requires jsonschema>=4.17.3, but you have jsonschema 3.2.0 which is incompatible.\n",
      "sagemaker 2.167.0 requires PyYAML==6.0, but you have pyyaml 5.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bcrypt-4.0.1 distro-1.8.0 docker-compose-1.29.2 dockerpty-0.4.1 docopt-0.6.2 jsonschema-3.2.0 paramiko-3.2.0 pynacl-1.5.0 python-dotenv-0.21.1 texttable-1.6.7 websocket-client-0.59.0\n"
     ]
    }
   ],
   "source": [
    "# 복수 개의 컨테이너가 유기적으로 묶여서 하나의 도커 애플리케이션으로 동작할 수 있도록 구성하는 도구로써 docker-compose 설치\n",
    "\n",
    "!pip install docker-compose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2eefb9-ef43-45c2-8be9-9439a2cf60d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4. 컨테이터 로컬에서 테스트하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "196c21a7-10d8-4d4a-b957-52acc406fccb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tf-custom-container-test-2023-07-28-09-20-06-008\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-svfmc:\n",
      "    command: train\n",
      "    container_name: er71fkryig-algo-1-svfmc\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: tf-custom-container-test\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-svfmc\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpviexpc3l/algo-1-svfmc/input:/opt/ml/input\n",
      "    - /tmp/tmpviexpc3l/algo-1-svfmc/output:/opt/ml/output\n",
      "    - /tmp/tmpviexpc3l/algo-1-svfmc/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpviexpc3l/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpviexpc3l/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating er71fkryig-algo-1-svfmc ... \n",
      "Creating er71fkryig-algo-1-svfmc ... done\n",
      "Attaching to er71fkryig-algo-1-svfmc\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,009 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,010 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,020 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,025 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,027 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,035 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,039 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,041 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,049 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,051 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m \n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m Training Env:\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m \n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m {\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"current_host\": \"algo-1-svfmc\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"current_instance_group\": \"homogeneousCluster\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"current_instance_group_hosts\": [],\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"current_instance_type\": \"local\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"distribution_hosts\": [\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m         \"algo-1-svfmc\"\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     ],\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"distribution_instance_groups\": [],\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m         \"algo-1-svfmc\"\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     ],\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"instance_groups\": [],\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"instance_groups_dict\": {},\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"is_hetero\": false,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"is_modelparallel_enabled\": null,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"is_smddpmprun_installed\": false,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"job_name\": \"tf-custom-container-test-2023-07-28-09-20-06-008\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"master_hostname\": \"algo-1-svfmc\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"num_neurons\": 0,\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m         \"current_host\": \"algo-1-svfmc\",\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m             \"algo-1-svfmc\"\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m         ]\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     },\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m }\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m \n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m Environment variables:\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m \n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_HOSTS=[\"algo-1-svfmc\"]\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_HPS={}\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-svfmc\",\"hosts\":[\"algo-1-svfmc\"]}\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_CURRENT_HOST=algo-1-svfmc\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_CURRENT_INSTANCE_TYPE=local\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_INSTANCE_GROUPS=[]\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_INSTANCE_GROUPS_DICT={}\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_IS_HETERO=false\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_NUM_NEURONS=0\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-svfmc\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-svfmc\"],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1-svfmc\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"tf-custom-container-test-2023-07-28-09-20-06-008\",\"log_level\":20,\"master_hostname\":\"algo-1-svfmc\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-svfmc\",\"hosts\":[\"algo-1-svfmc\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m \n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m \n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m /usr/bin/python3 train.py\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m \n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m \n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09,052 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:09.337691: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:11.208861: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:13.453046: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: UNKNOWN ERROR (34)\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2910 - accuracy: 0.9154\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9586\n",
      "\u001b[36mer71fkryig-algo-1-svfmc |\u001b[0m 2023-07-28 09:20:18,969 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmpviexpc3l/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpviexpc3l/algo-1-svfmc/output/success -> /tmp/tmpviexpc3l/artifacts/output\n",
      "INFO:root:creating /tmp/tmpviexpc3l/artifacts/model/1\n",
      "INFO:root:creating /tmp/tmpviexpc3l/artifacts/model/1/variables\n",
      "INFO:root:copying /tmp/tmpviexpc3l/model/1/variables/variables.data-00000-of-00001 -> /tmp/tmpviexpc3l/artifacts/model/1/variables\n",
      "INFO:root:copying /tmp/tmpviexpc3l/model/1/variables/variables.index -> /tmp/tmpviexpc3l/artifacts/model/1/variables\n",
      "INFO:root:creating /tmp/tmpviexpc3l/artifacts/model/1/assets\n",
      "INFO:root:copying /tmp/tmpviexpc3l/model/1/fingerprint.pb -> /tmp/tmpviexpc3l/artifacts/model/1\n",
      "INFO:root:copying /tmp/tmpviexpc3l/model/1/saved_model.pb -> /tmp/tmpviexpc3l/artifacts/model/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mer71fkryig-algo-1-svfmc exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "# arn:aws:iam::534520364753:role/service-role/AmazonSageMaker-ExecutionRole-20230725T174296 은 \n",
    "# 노트북 인스턴스 만들때,생성하는 IAM 을 복사해서 넣는다. 생성할 때마다 모두 다른 값이 나온다. \n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# 딥러닝 모델의 학습과 검증, 예측을 구현하기 위해 생성도니 모델 함수를 에스터메이터 객체에 적용함.\n",
    "estimator = Estimator(image_uri='tf-custom-container-test',\n",
    "                      role='arn:aws:iam::534520364753:role/service-role/AmazonSageMaker-ExecutionRole-20230725T174296',\n",
    "                      instance_count=1,\n",
    "                      instance_type='local')\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d736f222-8dd2-4e60-9046-c1183e6df063",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Amazon ECR로 컨테이너 푸시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915af49-94b4-4b5d-8346-c305f76c8ce7",
   "metadata": {},
   "source": [
    "##### 로컬 모드 테스트를 성공적으로 실행한 후 Docker 컨테이너를 Amazon ECR로 푸시하고 이를 사용하여 Training Job을 실행한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b18abc-fb64-4932-bef9-2205f8b7d89a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  6.656kB\n",
      "Step 1/4 : FROM tensorflow/tensorflow:latest-gpu-jupyter\n",
      " ---> 99c4601387b3\n",
      "Step 2/4 : RUN pip3 install sagemaker-training\n",
      " ---> Using cache\n",
      " ---> 62ff856baff2\n",
      "Step 3/4 : COPY train.py /opt/ml/code/train.py\n",
      " ---> Using cache\n",
      " ---> 180433f95498\n",
      "Step 4/4 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Using cache\n",
      " ---> 8bf1a121c329\n",
      "Successfully built 8bf1a121c329\n",
      "Successfully tagged tf-custom-container-test:latest\n",
      "The push refers to repository [534520364753.dkr.ecr.us-west-2.amazonaws.com/tf-custom-container-test]\n",
      "08a901fc453e: Preparing\n",
      "c7d4025fd6b9: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "1d39b76b247e: Preparing\n",
      "0d4550aff43c: Preparing\n",
      "2692c462eca5: Preparing\n",
      "305a9a2f982a: Preparing\n",
      "b8366c80bf4a: Preparing\n",
      "a073a40e4dcd: Preparing\n",
      "2ec1b5695a98: Preparing\n",
      "0b37f0d116f4: Preparing\n",
      "da5d2813a979: Preparing\n",
      "0eaa6e868aa5: Preparing\n",
      "1ca9136c7d36: Preparing\n",
      "dca2891e0e76: Preparing\n",
      "eaa2ed848ac5: Preparing\n",
      "ff3418b47754: Preparing\n",
      "2692c462eca5: Waiting\n",
      "d3dd91e05b94: Preparing\n",
      "a073a40e4dcd: Waiting\n",
      "305a9a2f982a: Waiting\n",
      "d49fe103257c: Preparing\n",
      "0eaa6e868aa5: Waiting\n",
      "e67ab25399cb: Preparing\n",
      "2ec1b5695a98: Waiting\n",
      "b8366c80bf4a: Waiting\n",
      "9a09b667a965: Preparing\n",
      "1ca9136c7d36: Waiting\n",
      "0b37f0d116f4: Waiting\n",
      "93b76ad9c95e: Preparing\n",
      "a2fdb4e1ecd1: Preparing\n",
      "dca2891e0e76: Waiting\n",
      "0ceb5c845fcf: Preparing\n",
      "6426a7216f78: Preparing\n",
      "eaa2ed848ac5: Waiting\n",
      "ec66d8cea54a: Preparing\n",
      "d49fe103257c: Waiting\n",
      "ff3418b47754: Waiting\n",
      "d3dd91e05b94: Waiting\n",
      "0ceb5c845fcf: Waiting\n",
      "9a09b667a965: Waiting\n",
      "93b76ad9c95e: Waiting\n",
      "6426a7216f78: Waiting\n",
      "a2fdb4e1ecd1: Waiting\n",
      "ec66d8cea54a: Waiting\n",
      "0d4550aff43c: Layer already exists\n",
      "1d39b76b247e: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "2692c462eca5: Layer already exists\n",
      "305a9a2f982a: Layer already exists\n",
      "b8366c80bf4a: Layer already exists\n",
      "a073a40e4dcd: Layer already exists\n",
      "2ec1b5695a98: Layer already exists\n",
      "0b37f0d116f4: Layer already exists\n",
      "da5d2813a979: Layer already exists\n",
      "1ca9136c7d36: Layer already exists\n",
      "0eaa6e868aa5: Layer already exists\n",
      "dca2891e0e76: Layer already exists\n",
      "eaa2ed848ac5: Layer already exists\n",
      "ff3418b47754: Layer already exists\n",
      "d49fe103257c: Layer already exists\n",
      "d3dd91e05b94: Layer already exists\n",
      "e67ab25399cb: Layer already exists\n",
      "93b76ad9c95e: Layer already exists\n",
      "9a09b667a965: Layer already exists\n",
      "a2fdb4e1ecd1: Layer already exists\n",
      "0ceb5c845fcf: Layer already exists\n",
      "6426a7216f78: Layer already exists\n",
      "08a901fc453e: Pushed\n",
      "ec66d8cea54a: Pushed\n",
      "c7d4025fd6b9: Pushed\n",
      "latest: digest: sha256:0dade290901c0f0ee1f21dbcb28f2d64dc861f81d0814f64acd1b85c3b3c7dcf size: 5756\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# 알고리듬 이름을 지정한다. \n",
    "algorithm_name=tf-custom-container-test\n",
    "\n",
    "# 로그인을 위해 계정 정보 파악\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# 현재 설정된 리전 이름을 얻기 (정의되어 있지 않으면, us-west-2 기본)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "# 534520364753.dkr.ecr.us-west-2.amazonaws.com/tf-custom-container-test\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# ECR에 레포지토리가 없다면, algorithm_name 생성\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# ECR에 get-login-password 와 docker-login 명령어로 aws 접속해서 ECR에 로그인하고 도커 인증함.\n",
    "\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# 로컬에서 이미지 이름으로 빌드하고 Fullname 으로 ECR 로 푸시함. \n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "# 주의 사항 : 만일 실행되지 않으면, IAM의 Role에 AmazonEC2ContainerRegistryFullAccess 정책과 AmazonS3FullAccess 정책을 추가하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f58f97c8-dbea-4cc2-9ed8-8dbdaaae5d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'534520364753.dkr.ecr.us-west-2.amazonaws.com/tf-custom-container-test:latest'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 컨테이너의 Amazon ECR 이미지를 호출\n",
    "\n",
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'tf-custom-container-test'\n",
    "tag = ':latest'\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "uri_suffix = 'amazonaws.com'\n",
    "\n",
    "byoc_image_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)\n",
    "\n",
    "byoc_image_uri\n",
    "# 도커 이미지가 있는 주소 이름\n",
    "# '534520364753.dkr.ecr.us-west-2.amazonaws.com/tf-custom-container-test:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60344440-0c1a-4bc4-9bdd-94395e343264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tf-custom-container-test-job-2023-07-28-09-23-10-436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-28 09:23:10 Starting - Starting the training job...\n",
      "2023-07-28 09:23:25 Starting - Preparing the instances for training......\n",
      "2023-07-28 09:24:22 Downloading - Downloading input data...\n",
      "2023-07-28 09:24:47 Training - Downloading the training image............\n",
      "2023-07-28 09:26:58 Training - Training image download completed. Training in progress.\u001b[34m2023-07-28 09:26:59,416 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-28 09:26:59,418 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-28 09:26:59,442 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-28 09:26:59,444 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-28 09:26:59,458 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-07-28 09:26:59,460 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-28 09:26:59,473 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"tf-custom-container-test-job-2023-07-28-09-23-10-436\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"tf-custom-container-test-job-2023-07-28-09-23-10-436\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 train.py\u001b[0m\n",
      "\u001b[34m2023-07-28 09:26:59,474 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2023-07-28 09:26:59.848059: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[0m\n",
      "\u001b[34mTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2023-07-28 09:27:02.210890: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[0m\n",
      "\u001b[34mTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\u001b[0m\n",
      "\u001b[34m#015    8192/11490434 [..............................] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  589824/11490434 [>.............................] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 7626752/11490434 [==================>...........] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01511490434/11490434 [==============================] - 0s 0us/step\u001b[0m\n",
      "\u001b[34m2023-07-28 09:27:05.606797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: UNKNOWN ERROR (34)\u001b[0m\n",
      "\u001b[34m2023-07-28 09:27:06.148823: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m#015   1/1875 [..............................] - ETA: 16:36 - loss: 2.4269 - accuracy: 0.0938#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  22/1875 [..............................] - ETA: 4s - loss: 1.7985 - accuracy: 0.4631   #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  42/1875 [..............................] - ETA: 4s - loss: 1.4361 - accuracy: 0.5781#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  63/1875 [>.............................] - ETA: 4s - loss: 1.1846 - accuracy: 0.6592#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  85/1875 [>.............................] - ETA: 4s - loss: 1.0213 - accuracy: 0.7107#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 106/1875 [>.............................] - ETA: 4s - loss: 0.9201 - accuracy: 0.7379#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 128/1875 [=>............................] - ETA: 4s - loss: 0.8477 - accuracy: 0.7593#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 150/1875 [=>............................] - ETA: 4s - loss: 0.7844 - accuracy: 0.7773#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 164/1875 [=>............................] - ETA: 5s - loss: 0.7547 - accuracy: 0.7854#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 185/1875 [=>............................] - ETA: 4s - loss: 0.7186 - accuracy: 0.7959#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 207/1875 [==>...........................] - ETA: 4s - loss: 0.6879 - accuracy: 0.8045#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 229/1875 [==>...........................] - ETA: 4s - loss: 0.6583 - accuracy: 0.8125#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 251/1875 [===>..........................] - ETA: 4s - loss: 0.6342 - accuracy: 0.8191#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 273/1875 [===>..........................] - ETA: 4s - loss: 0.6192 - accuracy: 0.8231#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 295/1875 [===>..........................] - ETA: 4s - loss: 0.6031 - accuracy: 0.8273#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 314/1875 [====>.........................] - ETA: 4s - loss: 0.5893 - accuracy: 0.8308#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 337/1875 [====>.........................] - ETA: 4s - loss: 0.5769 - accuracy: 0.8341#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 359/1875 [====>.........................] - ETA: 4s - loss: 0.5653 - accuracy: 0.8374#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 382/1875 [=====>........................] - ETA: 3s - loss: 0.5543 - accuracy: 0.8407#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 403/1875 [=====>........................] - ETA: 3s - loss: 0.5424 - accuracy: 0.8448#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 423/1875 [=====>........................] - ETA: 3s - loss: 0.5293 - accuracy: 0.8486#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 445/1875 [======>.......................] - ETA: 3s - loss: 0.5158 - accuracy: 0.8520#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 467/1875 [======>.......................] - ETA: 3s - loss: 0.5057 - accuracy: 0.8545#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 489/1875 [======>.......................] - ETA: 3s - loss: 0.4953 - accuracy: 0.8570#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 511/1875 [=======>......................] - ETA: 3s - loss: 0.4885 - accuracy: 0.8590#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 533/1875 [=======>......................] - ETA: 3s - loss: 0.4811 - accuracy: 0.8611#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 554/1875 [=======>......................] - ETA: 3s - loss: 0.4733 - accuracy: 0.8633#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 576/1875 [========>.....................] - ETA: 3s - loss: 0.4648 - accuracy: 0.8658#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 598/1875 [========>.....................] - ETA: 3s - loss: 0.4587 - accuracy: 0.8677#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 620/1875 [========>.....................] - ETA: 3s - loss: 0.4520 - accuracy: 0.8695#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 642/1875 [=========>....................] - ETA: 3s - loss: 0.4474 - accuracy: 0.8709#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 661/1875 [=========>....................] - ETA: 3s - loss: 0.4425 - accuracy: 0.8724#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 682/1875 [=========>....................] - ETA: 3s - loss: 0.4371 - accuracy: 0.8736#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 700/1875 [==========>...................] - ETA: 2s - loss: 0.4330 - accuracy: 0.8748#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 715/1875 [==========>...................] - ETA: 2s - loss: 0.4293 - accuracy: 0.8761#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 731/1875 [==========>...................] - ETA: 2s - loss: 0.4265 - accuracy: 0.8767#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 750/1875 [===========>..................] - ETA: 2s - loss: 0.4229 - accuracy: 0.8778#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 770/1875 [===========>..................] - ETA: 2s - loss: 0.4179 - accuracy: 0.8794#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 787/1875 [===========>..................] - ETA: 2s - loss: 0.4146 - accuracy: 0.8803#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 805/1875 [===========>..................] - ETA: 2s - loss: 0.4106 - accuracy: 0.8816#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 827/1875 [============>.................] - ETA: 2s - loss: 0.4064 - accuracy: 0.8826#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 849/1875 [============>.................] - ETA: 2s - loss: 0.4013 - accuracy: 0.8840#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 871/1875 [============>.................] - ETA: 2s - loss: 0.3974 - accuracy: 0.8851#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 893/1875 [=============>................] - ETA: 2s - loss: 0.3934 - accuracy: 0.8862#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 916/1875 [=============>................] - ETA: 2s - loss: 0.3897 - accuracy: 0.8871#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 939/1875 [==============>...............] - ETA: 2s - loss: 0.3865 - accuracy: 0.8879#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 961/1875 [==============>...............] - ETA: 2s - loss: 0.3828 - accuracy: 0.8890#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 984/1875 [==============>...............] - ETA: 2s - loss: 0.3797 - accuracy: 0.8898#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151006/1875 [===============>..............] - ETA: 2s - loss: 0.3762 - accuracy: 0.8908#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151028/1875 [===============>..............] - ETA: 2s - loss: 0.3725 - accuracy: 0.8919#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151049/1875 [===============>..............] - ETA: 2s - loss: 0.3694 - accuracy: 0.8926#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151067/1875 [================>.............] - ETA: 2s - loss: 0.3673 - accuracy: 0.8931#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151089/1875 [================>.............] - ETA: 1s - loss: 0.3647 - accuracy: 0.8938#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151111/1875 [================>.............] - ETA: 1s - loss: 0.3615 - accuracy: 0.8946#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151133/1875 [=================>............] - ETA: 1s - loss: 0.3591 - accuracy: 0.8953#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151155/1875 [=================>............] - ETA: 1s - loss: 0.3564 - accuracy: 0.8961#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151177/1875 [=================>............] - ETA: 1s - loss: 0.3537 - accuracy: 0.8970#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151199/1875 [==================>...........] - ETA: 1s - loss: 0.3509 - accuracy: 0.8979#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151221/1875 [==================>...........] - ETA: 1s - loss: 0.3488 - accuracy: 0.8986#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151243/1875 [==================>...........] - ETA: 1s - loss: 0.3463 - accuracy: 0.8994#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151265/1875 [===================>..........] - ETA: 1s - loss: 0.3436 - accuracy: 0.9002#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151287/1875 [===================>..........] - ETA: 1s - loss: 0.3414 - accuracy: 0.9009#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151307/1875 [===================>..........] - ETA: 1s - loss: 0.3395 - accuracy: 0.9014#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151330/1875 [====================>.........] - ETA: 1s - loss: 0.3370 - accuracy: 0.9021#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151352/1875 [====================>.........] - ETA: 1s - loss: 0.3347 - accuracy: 0.9027#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151374/1875 [====================>.........] - ETA: 1s - loss: 0.3323 - accuracy: 0.9035#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151396/1875 [=====================>........] - ETA: 1s - loss: 0.3305 - accuracy: 0.9039#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151419/1875 [=====================>........] - ETA: 1s - loss: 0.3280 - accuracy: 0.9047#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151441/1875 [======================>.......] - ETA: 1s - loss: 0.3258 - accuracy: 0.9053#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151464/1875 [======================>.......] - ETA: 1s - loss: 0.3236 - accuracy: 0.9061#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151486/1875 [======================>.......] - ETA: 0s - loss: 0.3211 - accuracy: 0.9068#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151506/1875 [=======================>......] - ETA: 0s - loss: 0.3193 - accuracy: 0.9072#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151529/1875 [=======================>......] - ETA: 0s - loss: 0.3177 - accuracy: 0.9076#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151552/1875 [=======================>......] - ETA: 0s - loss: 0.3158 - accuracy: 0.9082#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151574/1875 [========================>.....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9087#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151597/1875 [========================>.....] - ETA: 0s - loss: 0.3126 - accuracy: 0.9092#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151620/1875 [========================>.....] - ETA: 0s - loss: 0.3112 - accuracy: 0.9096#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151642/1875 [=========================>....] - ETA: 0s - loss: 0.3094 - accuracy: 0.9101#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151664/1875 [=========================>....] - ETA: 0s - loss: 0.3078 - accuracy: 0.9104#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151686/1875 [=========================>....] - ETA: 0s - loss: 0.3062 - accuracy: 0.9109#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151708/1875 [==========================>...] - ETA: 0s - loss: 0.3044 - accuracy: 0.9114#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151731/1875 [==========================>...] - ETA: 0s - loss: 0.3027 - accuracy: 0.9119#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151753/1875 [===========================>..] - ETA: 0s - loss: 0.3011 - accuracy: 0.9124#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151775/1875 [===========================>..] - ETA: 0s - loss: 0.2993 - accuracy: 0.9130#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151797/1875 [===========================>..] - ETA: 0s - loss: 0.2977 - accuracy: 0.9135#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151820/1875 [============================>.] - ETA: 0s - loss: 0.2964 - accuracy: 0.9140#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151843/1875 [============================>.] - ETA: 0s - loss: 0.2945 - accuracy: 0.9145#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151866/1875 [============================>.] - ETA: 0s - loss: 0.2933 - accuracy: 0.9149#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151875/1875 [==============================] - 5s 2ms/step - loss: 0.2927 - accuracy: 0.9151\u001b[0m\n",
      "\u001b[34m2023-07-28 09:27:11.516902: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31360000 exceeds 10% of free system memory.\u001b[0m\n",
      "\u001b[34m#015  1/313 [..............................] - ETA: 44s - loss: 0.0952 - accuracy: 0.9688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 40/313 [==>...........................] - ETA: 0s - loss: 0.1701 - accuracy: 0.9422 #010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 80/313 [======>.......................] - ETA: 0s - loss: 0.1991 - accuracy: 0.9391#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015119/313 [==========>...................] - ETA: 0s - loss: 0.1898 - accuracy: 0.9428#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015158/313 [==============>...............] - ETA: 0s - loss: 0.1982 - accuracy: 0.9393#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015197/313 [=================>............] - ETA: 0s - loss: 0.1815 - accuracy: 0.9445#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015237/313 [=====================>........] - ETA: 0s - loss: 0.1670 - accuracy: 0.9498#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015277/313 [=========================>....] - ETA: 0s - loss: 0.1512 - accuracy: 0.9545#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015313/313 [==============================] - 1s 1ms/step - loss: 0.1488 - accuracy: 0.9554\u001b[0m\n",
      "\u001b[34m2023-07-28 09:27:13,476 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-07-28 09:27:34 Uploading - Uploading generated training model\n",
      "2023-07-28 09:27:34 Completed - Training job completed\n",
      "Training seconds: 193\n",
      "Billable seconds: 193\n"
     ]
    }
   ],
   "source": [
    "# 이전 단계에서 검색한 ecr_image를 사용하여 SageMaker Estimator 객체를 구성gka.\n",
    "# byoc_image_uri로 SageMaker estimator를 구성하고 Amazon EC2 인스턴스에서 훈련 작업을 시작한다.\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "estimator = Estimator(image_uri=byoc_image_uri,\n",
    "                      role=get_execution_role(),\n",
    "                      base_job_name='tf-custom-container-test-job',\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.m5.large')\n",
    "\n",
    "# 모델 훈련\n",
    "estimator.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31e7d57c-2c2b-4a2a-beed-10490517c7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference:2.11.0-cpu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자체 컨테이너를 사용해 모델을 배포하려면, 1) 커스텀 추론 컨테이너를 내가 만들어서 사용하거나,  \n",
    "# 2) 퍼블릭하게 공개된 TensorFlow 모델을 배포할 수 있는 AWSframework 컨테이너를 그대로 사용할 수도 있다. \n",
    "\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# image uris 호출\n",
    "from sagemaker import image_uris\n",
    "\n",
    "# mnist 데이터셋의 필기 숫자를 읽기 위해서는 하나의 모델 샘플에서\n",
    "# 기존의 모델을 훈련하는 데 사용한 동일한 도커 컨테이너 이미지 URI(범용 리소스 식별자)를 추론으로 사용함.\n",
    "\n",
    "container = image_uris.retrieve(framework='tensorflow',region='us-west-2',version='2.11.0',\n",
    "                    image_scope='inference',instance_type='ml.m5.xlarge')\n",
    "\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e7caa43-638b-44e6-8840-75c1bfa492d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: tf-custom-container-test-job-2023-07-28-09-28-34-043\n",
      "INFO:sagemaker:Creating endpoint-config with name tf-custom-container-test-job-2023-07-28-09-28-34-043\n",
      "INFO:sagemaker:Creating endpoint with name tf-custom-container-test-job-2023-07-28-09-28-34-043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---!"
     ]
    }
   ],
   "source": [
    "# 위의 필기 숫자 인식 model 모델 엔터티 및 엔드포인트 구성하고 엔드포인트를 생성\n",
    "predictor = estimator.deploy(1,instance_type='ml.m5.xlarge',image_uri=container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23679981-7191-454d-9aba-f5427a8211f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:generated new fontManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터셋에서 샘플을 가져와 검증 \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# MNIST 데이터셋을 로드하고 훈련 및 테스트셋으로 분할\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련 데이터넷에서 랜덤으로 표본을 선택\n",
    "example_index = np.random.randint(0, x_train.shape[0])\n",
    "example_image = x_train[example_index]\n",
    "example_label = y_train[example_index]\n",
    "\n",
    "# 결과를 레이블에 출력하고 필기체 이미지를 보여줌\n",
    "print(f\"Label: {example_label}\")\n",
    "plt.imshow(example_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aca2d851-ddc2-4daf-9dcc-fbf3cb3d214c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n    \"predictions\": [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\\n    ]\\n}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "data = {\"instances\": example_image.tolist()}\n",
    "\n",
    "# JSONSerializer를 사용해 JSON 형태로 예측 업데이트\n",
    "predictor.serializer=JSONSerializer() \n",
    "\n",
    "# 예측 생성\n",
    "predictor.predict(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29924e0e-9e73-4d56-b79a-e6eace8930c4",
   "metadata": {},
   "source": [
    "#### 참고: https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-training-container.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e65ede-8a6f-4d7d-8e5e-f486daff232e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
